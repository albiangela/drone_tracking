{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5fa2fe-e4d7-40ab-914d-767062d5e9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2.aruco as aruco\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a5c2c06-99b5-44c1-9d00-83865248e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to detect ArUco markers in image tiles and compute centroids\n",
    "def detect_aruco_markers_in_tiles(frame, tile_size=1200, overlap=200):\n",
    "    h, w = frame.shape[:2]\n",
    "    detected_corners = []\n",
    "    detected_ids = []\n",
    "    centroids = {}\n",
    "\n",
    "    # Collect detections from all tiles\n",
    "    all_corners = []\n",
    "    all_ids = []\n",
    "    all_centroids = {}\n",
    "\n",
    "    for y in range(0, h, tile_size - overlap):\n",
    "        for x in range(0, w, tile_size - overlap):\n",
    "            start_x = max(0, x - overlap)\n",
    "            start_y = max(0, y - overlap)\n",
    "            end_x = min(w, x + tile_size + overlap)\n",
    "            end_y = min(h, y + tile_size + overlap)\n",
    "\n",
    "            expanded_tile = frame[start_y:end_y, start_x:end_x]\n",
    "            \n",
    "            # Convert to grayscale and detect markers in the expanded tile\n",
    "            gray = cv2.cvtColor(expanded_tile, cv2.COLOR_BGR2GRAY)\n",
    "            # corners, ids, _ = aruco_detector.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMETERS)\n",
    "            corners, ids, _ = aruco_detector.detectMarkers(gray)\n",
    "            if ids is not None:\n",
    "                for corner, id_ in zip(corners, ids):\n",
    "                    id_scalar = id_[0]\n",
    "                    if id_scalar in VALID_IDS:\n",
    "                        # Adjust corner coordinates relative to the original frame\n",
    "                        corner[:, :, 0] += start_x\n",
    "                        corner[:, :, 1] += start_y\n",
    "\n",
    "                        all_corners.append(corner)\n",
    "                        all_ids.append(id_scalar)\n",
    "\n",
    "                        # Compute centroid\n",
    "                        centroid = np.mean(corner[0], axis=0)\n",
    "                        if id_scalar in all_centroids:\n",
    "                            # Average centroids if marker appears in multiple tiles\n",
    "                            all_centroids[id_scalar].append(centroid)\n",
    "                        else:\n",
    "                            all_centroids[id_scalar] = [centroid]\n",
    "\n",
    "    # Merge detections from all tiles\n",
    "    for id_scalar, centroids_list in all_centroids.items():\n",
    "        if len(centroids_list) > 1:\n",
    "            # Average centroids detected in multiple tiles\n",
    "            merged_centroid = np.mean(centroids_list, axis=0)\n",
    "        else:\n",
    "            merged_centroid = centroids_list[0]\n",
    "        centroids[id_scalar] = merged_centroid\n",
    "\n",
    "    # Draw detected markers on the frame\n",
    "    if all_ids:\n",
    "        detected_ids = np.array(all_ids)\n",
    "        detected_corners = all_corners\n",
    "        cv2.aruco.drawDetectedMarkers(frame, detected_corners, detected_ids)\n",
    "    else:\n",
    "        detected_ids = None\n",
    "\n",
    "    return frame, centroids, detected_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c9c6923-3ce4-4baf-b872-74a923b3faa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed frame 500\n",
      "Processed frame 600\n",
      "Processed frame 700\n",
      "[INFO] Video processing complete.\n",
      "[INFO] Centroids data saved to 'centroids_data_moving_ema.json'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the path to the input video and the ArUCo type\n",
    "video_path = '/Volumes/SSD_various/DATA/sharks/2024_sequences/sequence_20240303_070126703_DJI_0257_trim.MP4'\n",
    "output_video_path = '/Volumes/SSD_various/DATA/sharks/2024_sequences/registered_clips/sequence_20240303_070126703_DJI_0257_trim_ema_alpha1.MP4'\n",
    "\n",
    "# Load the ArUCo dictionary\n",
    "aruco_type = cv2.aruco.DICT_4X4_50\n",
    "ARUCO_DICT = cv2.aruco.getPredefinedDictionary(aruco_type)\n",
    "ARUCO_PARAMETERS = cv2.aruco.DetectorParameters()\n",
    "aruco_detector = cv2.aruco.ArucoDetector(ARUCO_DICT,ARUCO_PARAMETERS)\n",
    "\n",
    "# Specify the valid marker IDs\n",
    "VALID_IDS = [0, 1, 3]\n",
    "\n",
    "# Smoothing factor for exponential moving average\n",
    "alpha = 0.9  # Adjust between 0 and 1; lower values mean more smoothing\n",
    "\n",
    "# Initialize smoothed centroids history\n",
    "smoothed_centroids_history = {}\n",
    "unsmoothed_centroids_history = {}\n",
    "smoothed_centroids_history_full = {}\n",
    "# Frame range for processing\n",
    "start_frame = 500  # Change to your desired starting frame\n",
    "end_frame = 700   # Change to your desired ending frame\n",
    "\n",
    "\n",
    "\n",
    "# Open the input video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    print(\"[ERROR] Unable to open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Set the starting frame\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "# Get video properties\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "# Read the first frame and detect markers\n",
    "ret, first_frame = cap.read()\n",
    "if not ret:\n",
    "    print(\"[ERROR] Unable to read the first frame.\")\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    exit()\n",
    "\n",
    "first_frame_detected, first_centroids, first_ids = detect_aruco_markers_in_tiles(first_frame)\n",
    "if first_ids is None or len(first_ids) < 2:\n",
    "    print(\"[ERROR] Not enough valid markers detected in the first frame.\")\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    exit()\n",
    "\n",
    "# Initialize smoothed centroids with the first frame's centroids\n",
    "for id_, centroid in first_centroids.items():\n",
    "    smoothed_centroids_history[id_] = centroid.copy()\n",
    "\n",
    "# Write the first frame to the output video\n",
    "out.write(first_frame_detected)\n",
    "\n",
    "# Initialize previous valid transformation\n",
    "# prev_frame_index = 0\n",
    "prev_transformation = None\n",
    "\n",
    "# Buffer to store frames needing interpolation\n",
    "buffered_frames = []\n",
    "buffered_indices = []\n",
    "\n",
    "frame_count = start_frame\n",
    "\n",
    "while cap.isOpened() and frame_count <= end_frame:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    detected_frame, centroids, ids = detect_aruco_markers_in_tiles(frame)\n",
    "    if ids is not None and len(ids) >= 2:\n",
    "        smoothed_centroids = {}\n",
    "        for id_ in ids:\n",
    "            centroid = centroids[id_]\n",
    "    \n",
    "            # Initialize history for unsmoothed centroids if not present\n",
    "            if id_ not in unsmoothed_centroids_history:\n",
    "                unsmoothed_centroids_history[id_] = []\n",
    "            unsmoothed_centroids_history[id_].append(centroid.tolist())\n",
    "    \n",
    "            # Apply exponential smoothing for smoothed centroids\n",
    "            if id_ in smoothed_centroids_history:\n",
    "                smoothed_centroid = alpha * centroid + (1 - alpha) * smoothed_centroids_history[id_]\n",
    "                smoothed_centroids_history[id_] = smoothed_centroid.copy()\n",
    "            else:\n",
    "                smoothed_centroid = centroid.copy()\n",
    "                smoothed_centroids_history[id_] = smoothed_centroid.copy()\n",
    "    \n",
    "            # Initialize history for smoothed centroids if not present\n",
    "            if id_ not in smoothed_centroids_history_full:\n",
    "                smoothed_centroids_history_full[id_] = []\n",
    "            smoothed_centroids_history_full[id_].append(smoothed_centroid.tolist())\n",
    "    \n",
    "            # Store smoothed centroids for the current frame\n",
    "            smoothed_centroids[id_] = smoothed_centroid\n",
    "        \n",
    "    else:\n",
    "        smoothed_centroids = {}\n",
    "        print(f\"[INFO] Frame {frame_count}: Not enough valid markers detected.\")\n",
    "\n",
    "    # Find common markers between current frame and the first frame\n",
    "    matched_ids = set(first_ids).intersection(set(ids)) if ids is not None else set()\n",
    "    if len(matched_ids) >= 2:\n",
    "        # Use centroids of matched markers for transformation estimation\n",
    "        pts_src = []\n",
    "        pts_dst = []\n",
    "        for id_ in matched_ids:\n",
    "            pts_src.append(smoothed_centroids[id_])\n",
    "            pts_dst.append(first_centroids[id_])\n",
    "\n",
    "        pts_src = np.array(pts_src)\n",
    "        pts_dst = np.array(pts_dst)\n",
    "\n",
    "        if len(matched_ids) >= 3:\n",
    "            # Compute affine transformation\n",
    "            M, inliers = cv2.estimateAffine2D(pts_src, pts_dst, method=cv2.RANSAC)\n",
    "        else:\n",
    "            # Compute similarity transformation\n",
    "            \n",
    "            M, inliers = cv2.estimateAffinePartial2D(pts_src, pts_dst, method=cv2.RANSAC)\n",
    "\n",
    "        if M is not None:\n",
    "            # We have a valid transformation\n",
    "            # If we have buffered frames, interpolate transformations\n",
    "            if buffered_frames:\n",
    "                # Interpolate transformations between prev_transformation and M\n",
    "                num_buffered = len(buffered_frames)\n",
    "                for i, (buf_frame, buf_index) in enumerate(zip(buffered_frames, buffered_indices)):\n",
    "                    t = (i + 1) / (num_buffered + 1)\n",
    "                    # Linear interpolation of transformation matrices\n",
    "                    interpolated_M = (1 - t) * prev_transformation + t * M\n",
    "                    warped_frame = cv2.warpAffine(buf_frame, interpolated_M, (width, height))\n",
    "                    out.write(warped_frame)\n",
    "                # Clear the buffers\n",
    "                buffered_frames = []\n",
    "                buffered_indices = []\n",
    "\n",
    "            # Apply transformation to current frame\n",
    "            warped_frame = cv2.warpAffine(frame, M, (width, height))\n",
    "            out.write(warped_frame)\n",
    "\n",
    "            # Update previous valid transformation\n",
    "            prev_transformation = M.copy()\n",
    "        else:\n",
    "            print(f\"[INFO] Frame {frame_count}: Transformation could not be computed.\")\n",
    "            # Buffer the frame\n",
    "            buffered_frames.append(frame)\n",
    "            buffered_indices.append(frame_count)\n",
    "    else:\n",
    "        print(f\"[INFO] Frame {frame_count}: Not enough matched markers.\")\n",
    "        # Buffer the frame\n",
    "        buffered_frames.append(frame)\n",
    "        buffered_indices.append(frame_count)\n",
    "\n",
    "    if frame_count % 100 == 0:\n",
    "        print(f\"Processed frame {frame_count}\")\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "# After processing all frames, handle any remaining buffered frames\n",
    "if buffered_frames and prev_transformation is not None:\n",
    "    print(\"[INFO] Processing remaining buffered frames at the end of the video.\")\n",
    "    for buf_frame in buffered_frames:\n",
    "        # Use the last known valid transformation\n",
    "        warped_frame = cv2.warpAffine(buf_frame, prev_transformation, (width, height))\n",
    "        out.write(warped_frame)\n",
    "elif buffered_frames:\n",
    "    print(\"[INFO] No valid transformation available for remaining buffered frames. Writing original frames.\")\n",
    "    for buf_frame in buffered_frames:\n",
    "        out.write(buf_frame)\n",
    "\n",
    "# Release video objects\n",
    "cap.release()\n",
    "out.release()\n",
    "print(\"[INFO] Video processing complete.\")\n",
    "\n",
    "# Save the data to a JSON file\n",
    "output_data = {\n",
    "    \"non_smoothed_centroids\": {str(k): np.array(v).tolist() for k, v in unsmoothed_centroids_history.items()},\n",
    "    \"smoothed_centroids\": {str(k): np.array(v).tolist() for k, v in smoothed_centroids_history_full.items()},\n",
    "}\n",
    "\n",
    "with open('centroids_data_moving_ema.json', 'w') as f:\n",
    "    json.dump(output_data, f)\n",
    "\n",
    "print(\"[INFO] Centroids data saved to 'centroids_data_moving_ema.json'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf8d2c2-5b7a-4f00-80b8-f76363b6e980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
